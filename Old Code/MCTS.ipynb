{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/fezilemahlangu/Reinforcement-Learning-Project/blob/master/MCTS.ipynb",
      "authorship_tag": "ABX9TyP/bi8A/NRYvoTlTeB3qRl4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fezilemahlangu/Reinforcement-Learning-Project/blob/master/MCTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "AK86zImAe8MW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75VyHPAnYk2e"
      },
      "outputs": [],
      "source": [
        "#https://towardsdatascience.com/deep-reinforcement-learning-and-monte-carlo-tree-search-with-connect-4-ba22a4713e7a\n",
        "\n",
        "#https://ai-boson.github.io/mcts/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install -y cmake\n",
        "!apt-get install -y build-essential autoconf libtool pkg-config\n",
        "!apt-get install flex bison libbz2-dev\n",
        "!pip install nle\n",
        "!pip install minihack\n",
        "# !python -m minihack.scripts.env_list\n",
        "!pip install gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "id": "ASHEtNDpe2BT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dd749c5-f388-404d-f07b-d608f110e492"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,217 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,257 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Fetched 8,553 kB in 5s (1,741 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "29 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  automake autotools-dev file libmagic-mgc libmagic1 libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc gettext libtool-doc gcj-jdk\n",
            "  m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev file libmagic-mgc libmagic1 libsigsegv2\n",
            "  libtool m4\n",
            "0 upgraded, 9 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 1,551 kB of archives.\n",
            "After this operation, 10.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\n",
            "Fetched 1,551 kB in 1s (1,655 kB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../1-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../2-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "Preparing to unpack .../3-libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../4-m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../5-autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../6-autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../7-automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Selecting previously unselected package libtool.\n",
            "Preparing to unpack .../8-libtool_2.4.6-2_all.deb ...\n",
            "Unpacking libtool (2.4.6-2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Setting up libtool (2.4.6-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libbz2-dev is already the newest version (1.0.6-8.1ubuntu0.2).\n",
            "libbz2-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libbison-dev libfl-dev libfl2\n",
            "Suggested packages:\n",
            "  bison-doc flex-doc\n",
            "The following NEW packages will be installed:\n",
            "  bison flex libbison-dev libfl-dev libfl2\n",
            "0 upgraded, 5 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 938 kB of archives.\n",
            "After this operation, 2,925 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 flex amd64 2.6.4-6 [316 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libbison-dev amd64 2:3.0.4.dfsg-1build1 [339 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 bison amd64 2:3.0.4.dfsg-1build1 [266 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfl2 amd64 2.6.4-6 [11.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfl-dev amd64 2.6.4-6 [6,320 B]\n",
            "Fetched 938 kB in 1s (1,089 kB/s)\n",
            "Selecting previously unselected package flex.\n",
            "(Reading database ... 124284 files and directories currently installed.)\n",
            "Preparing to unpack .../flex_2.6.4-6_amd64.deb ...\n",
            "Unpacking flex (2.6.4-6) ...\n",
            "Selecting previously unselected package libbison-dev:amd64.\n",
            "Preparing to unpack .../libbison-dev_2%3a3.0.4.dfsg-1build1_amd64.deb ...\n",
            "Unpacking libbison-dev:amd64 (2:3.0.4.dfsg-1build1) ...\n",
            "Selecting previously unselected package bison.\n",
            "Preparing to unpack .../bison_2%3a3.0.4.dfsg-1build1_amd64.deb ...\n",
            "Unpacking bison (2:3.0.4.dfsg-1build1) ...\n",
            "Selecting previously unselected package libfl2:amd64.\n",
            "Preparing to unpack .../libfl2_2.6.4-6_amd64.deb ...\n",
            "Unpacking libfl2:amd64 (2.6.4-6) ...\n",
            "Selecting previously unselected package libfl-dev:amd64.\n",
            "Preparing to unpack .../libfl-dev_2.6.4-6_amd64.deb ...\n",
            "Unpacking libfl-dev:amd64 (2.6.4-6) ...\n",
            "Setting up flex (2.6.4-6) ...\n",
            "Setting up libbison-dev:amd64 (2:3.0.4.dfsg-1build1) ...\n",
            "Setting up libfl2:amd64 (2.6.4-6) ...\n",
            "Setting up bison (2:3.0.4.dfsg-1build1) ...\n",
            "update-alternatives: using /usr/bin/bison.yacc to provide /usr/bin/yacc (yacc) in auto mode\n",
            "Setting up libfl-dev:amd64 (2.6.4-6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nle\n",
            "  Downloading nle-0.8.1.tar.gz (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 5.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from nle) (1.21.6)\n",
            "Requirement already satisfied: gym>=0.15 in /usr/local/lib/python3.7/dist-packages (from nle) (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.15->nle) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.15->nle) (4.13.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.15->nle) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.15->nle) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.15->nle) (4.1.1)\n",
            "Building wheels for collected packages: nle\n",
            "  Building wheel for nle (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nle: filename=nle-0.8.1-cp37-cp37m-linux_x86_64.whl size=2883122 sha256=b68c228c96270e7d5b36035aac2013ac192b40a7ec6101bf8860ae7bd7443436\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/43/b7/00eec64b2f64dc45883624bcb42a969645c86814ea751c6299\n",
            "Successfully built nle\n",
            "Installing collected packages: pybind11, nle\n",
            "Successfully installed nle-0.8.1 pybind11-2.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting minihack\n",
            "  Downloading minihack-0.1.3.tar.gz (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 5.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nle>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from minihack) (0.8.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from minihack) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from minihack) (1.21.6)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from nle>=0.8.0->minihack) (2.10.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym->minihack) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym->minihack) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->minihack) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->minihack) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym->minihack) (4.1.1)\n",
            "Building wheels for collected packages: minihack\n",
            "  Building wheel for minihack (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minihack: filename=minihack-0.1.3-py3-none-any.whl size=261792 sha256=ee72162a682f7f52411bc6cc85d2377740109d46fe3b05a2639f013e3fe7657f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/b0/50/bb8c09fe5befa92b343025c26d614c5fa312f1edb432cc9580\n",
            "Successfully built minihack\n",
            "Installing collected packages: minihack\n",
            "Successfully installed minihack-0.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.1)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.9.24)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=33609312966a0f228676d53e39ca1c91c6ae496f2173baadf6995d4eaaf7c7a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[box2d]"
      ],
      "metadata": {
        "id": "6K0STqMTz0sp",
        "outputId": "7e439bc0-5b90-4712-81b2-251800d9c4e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.7/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (4.13.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 76 kB/s \n",
            "\u001b[?25hCollecting box2d-py==2.3.5\n",
            "  Downloading box2d_py-2.3.5-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 71.1 MB/s \n",
            "\u001b[?25hCollecting swig==4.*\n",
            "  Downloading swig-4.1.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[box2d]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.9.0)\n",
            "Installing collected packages: swig, pygame, box2d-py\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "MxuFUSFZfOwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import nle\n",
        "import minihack\n",
        "from gym import spaces\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import torch\n",
        "import random\n",
        "from minihack import RewardManager\n",
        "from collections import defaultdict\n",
        "from minihack import reward_manager\n",
        "# import numpy as np\n",
        "# from minihack import RewardManager\n",
        "# from gym import spaces\n",
        "from nle import nethack\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "yrhieh3LfQMj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import gym\n",
        "# import minihack\n",
        "# from minihack import reward_manager\n",
        "# import numpy as np\n",
        "# from minihack import RewardManager\n",
        "# from gym import spaces\n",
        "# from nle import nethack\n",
        "# from numpy.lib.function_base import select\n",
        "\n",
        "# class BasicWrapper(gym.Wrapper):\n",
        "#     def __init__(self, env, seed=0, maxSteps = 10000):\n",
        "#         super().__init__(env)\n",
        "#         self.env = env\n",
        "#         self.seedCustom = seed\n",
        "#         self.maxSteps = maxSteps\n",
        "#         self.augmentedReward = 0\n",
        "#         self.seenStates = None\n",
        "#         self.currStep = 0\n",
        "#         self.repeatNum = 0\n",
        "#         # self.oldest = None\n",
        "#         # self.secOldest = None\n",
        "#         # self.secNewest= None\n",
        "#         # self.newest = None\n",
        "#         # print(\"NOTE: in here the max steps are set in the construction - change this as desired but keep in mind many steps are needed since a lot of exploring is needed\")\n",
        "#         # print(\"NOTE: Changing the seed if done, must be done here in initialising the class\")\n",
        "#         # print(\"IFF this is done, he seed used in the custom gym will be different and hence this change must be accounted for there as well\")\n",
        "#         # print(\"The default seed will be set to 0 in all cases as a standard seed - which allows for us to compare results\")\n",
        "#         # print(\"hence changing the seed is not advisable \\n environment has been initialised\")\n",
        "#     def fullReset(self):\n",
        "#         self.seenStates = None\n",
        "#         self.currStep = 0\n",
        "#         self.repeatNum = 0\n",
        "\n",
        "\n",
        "#     def reset(self):\n",
        "#         self.env.seed(self.seedCustom)\n",
        "#         state = self.env.reset()\n",
        "#         state = self.selectObs(state)\n",
        "#         return state\n",
        "\n",
        "#     def lookThroughDict(self, temp):\n",
        "#         solidStone = [73,116,39,115,32,115,111,108,105,100,32,115,116,111,110,101,46]\n",
        "#                     #   73 116 39 115 32 115 111 108 105 100 32 115 116 111 110 101 46 \n",
        "#         whatStrange = [87,104 ,97, 116, 32, 97, 32, 115, 116, 114, 97, 110, 103, 101, 32, 100, 105, 114, 101, 99, 116 ,105 ,111 ,110 ,33 ,32 ,32 ,78 ,101 ,118  ] # ,101 ,114 ,32 ,109 ,105 ,110 ,100 ,46\n",
        "#         nothingZap = [89, 111, 117, 32 ,100 ,111 ,110 ,39 ,116, 32, 104, 97, 118, 101, 32, 97 ,110, 121, 116, 104, 105, 110, 103, 32] #  ,116, 111, 32, 122, 97, 112, 46 \n",
        "#         whatDir = [73, 110, 32 ,119 ,104 ,97 ,116 ,32 ,100 ,105 ,114 ,101 ,99] # ,116 ,105 ,111 ,110 ,63 \n",
        "#         noDoor = [89, 111, 117, 32, 115, 101, 101, 32 ,110 ,111 ,32 ,100 ,111 ,111 ,114 ,32 ,116] # ,101 ,114 ,101 ,46  at the end missing here\n",
        "#         cnt = 0 \n",
        "#         punishmentReward = 0.2\n",
        "#         isMessage = False\n",
        "#         solid = True\n",
        "#         for char in solidStone:\n",
        "#             if temp[cnt] != char:\n",
        "#                 solid = False\n",
        "#                 break\n",
        "                \n",
        "#                 # break\n",
        "#             cnt += 1\n",
        "#         if solid:\n",
        "#             self.augmentedReward -= punishmentReward\n",
        "#             return\n",
        "#         strange = True\n",
        "#         for char in whatStrange:\n",
        "#             if temp[cnt] != char:\n",
        "#                 strange = False\n",
        "#                 # self.augmentedReward -= 0.3\n",
        "#                 # return\n",
        "#                 break\n",
        "#             cnt += 1\n",
        "#         if strange:\n",
        "#             self.augmentedReward -= punishmentReward\n",
        "#             return\n",
        "\n",
        "#         zap = True\n",
        "#         for char in nothingZap:\n",
        "#             if temp[cnt] != char:\n",
        "#                 strange = False\n",
        "#                 # self.augmentedReward -= 0.3\n",
        "#                 # return\n",
        "#                 break\n",
        "#             cnt += 1\n",
        "#         if zap:\n",
        "#             self.augmentedReward -= punishmentReward\n",
        "#             return\n",
        "#         whatDirec = True\n",
        "#         for char in whatDir:\n",
        "#             if temp[cnt] != char:\n",
        "#                 whatDirec = False\n",
        "#                 # self.augmentedReward -= 0.3\n",
        "#                 # return\n",
        "#                 break\n",
        "#             cnt += 1\n",
        "#         if whatDirec:\n",
        "#             self.augmentedReward -= punishmentReward\n",
        "#             return\n",
        "#         noDoorHere = True\n",
        "#         for char in noDoor:\n",
        "#             if temp[cnt] != char:\n",
        "#                 noDoorHere = False\n",
        "#                 # self.augmentedReward -= 0.3\n",
        "#                 # return\n",
        "#                 break\n",
        "#             cnt += 1\n",
        "#         if noDoorHere:\n",
        "#             self.augmentedReward -= punishmentReward\n",
        "#             return\n",
        "#         else:\n",
        "#             self.augmentedReward += 0.01\n",
        "#             return\n",
        "\n",
        "#     def rewardExploration(self, temp):\n",
        "#         seenBefore = False\n",
        "        \n",
        "#         # for state in self.seenStates:\n",
        "#         #     if np.all(state == temp):\n",
        "#         #         self.repeatNum += 1\n",
        "#         #         self.augmentedReward -= 0.0025 * self.repeatNum\n",
        "#         #         # seenBefore = True\n",
        "#         #         return\n",
        "#         # self.augmentedReward += 5\n",
        "        \n",
        "        \n",
        "\n",
        "#     def selectObs(self, obs, desired=[\"chars\",\"message\",\"inv_letters\"]):\n",
        "#         tempState = np.array(())\n",
        "#         for desire in desired:\n",
        "#             temp = obs[desire]\n",
        "#             if desire == \"message\":\n",
        "#                 self.lookThroughDict(temp)\n",
        "#             temp = np.array(temp)\n",
        "#             temp = temp.astype(int)\n",
        "#             temp = temp.flatten()\n",
        "#             tempState = np.append(tempState, temp)\n",
        "#         return tempState\n",
        "\n",
        "#     def step(self, action, maxLength=10000):\n",
        "#         self.currStep += 1\n",
        "#         self.augmentedReward = 0\n",
        "#         next_state, reward, done, info = self.env.step(action)\n",
        "#         # if np.any(self.seenStates != None):\n",
        "#         #     self.rewardExploration(next_state[\"chars\"])\n",
        "#         #     self.seenStates.append(next_state[\"chars\"])\n",
        "#         next_state = self.selectObs(next_state)\n",
        "#         self.lookThroughDict(next_state)\n",
        "#         # if np.any(self.seenStates != None):\n",
        "#         #     self.rewardExploration(next_state)\n",
        "#         #     self.seenStates.append(next_state)\n",
        "#         # else:\n",
        "#         #     self.seenStates = [next_state]\n",
        "#         reward += self.augmentedReward\n",
        "#         # if done == True:\n",
        "#         #     if reward != 2:\n",
        "#         #         reward = -0.0105*(self.maxSteps-self.currStep) - 0.0105*(self.maxSteps) \n",
        "#         #     elif reward == 2: \n",
        "#         #         reward = 50\n",
        "#         # elif reward != -0.01 and reward != 20 and reward != 40:\n",
        "#         #     reward -= 0.02\n",
        "#         # if reward == 20:\n",
        "#         #     print(\"it equipped the wand\")\n",
        "#         # if reward == 40:\n",
        "#         #     print(\"it killed the minotaur\")\n",
        "#         # if np.any(self.seenStates == None):\n",
        "#         #     self.seenStates = [[next_state]]\n",
        "#         # else:\n",
        "#         # self.augmentedReward = 0\n",
        "#         # self.oldest = None\n",
        "#         # self.secOldest = None\n",
        "#         # self.secNewest= None\n",
        "#         # self.newest = None\n",
        "#         # if np.all(self.newest == None):\n",
        "#         #     self.newest = next_state\n",
        "#         # elif np.all(self.newest != None):\n",
        "#         #     if np.all(self.secNewest == None):\n",
        "#         #         self.secNewest = self.newest\n",
        "#         #         self.newest = next_state\n",
        "#         #     else:\n",
        "#         #         if np.all(self.secOldest == None):\n",
        "#         #             self.secOldest = self.secNewest\n",
        "#         #             self.secNewest = self.newest\n",
        "#         #             self.newest = next_state\n",
        "#         #         else:\n",
        "#         #             if np.all(next_state == self.secOldest):\n",
        "#         #                 reward -= 0.02\n",
        "#         #             if np.all(next_state == self.secNewest):\n",
        "#         #                 reward -= 0.02\n",
        "#         #             if np.all(next_state == self.newest):\n",
        "#         #                 reward -= 0.02\n",
        "#         return next_state, reward, done, info\n",
        "\n",
        "# def createActionSpace():\n",
        "#     moves = tuple(nethack.CompassDirection)\n",
        "#     navActions = moves + (\n",
        "#         # nethack.Command.APPLY,\n",
        "#         # nethack.Command.AUTOPICKUP,\n",
        "#         # nethack.Command.CAST,\n",
        "#         # nethack.Command.CLOSE,\n",
        "#         # nethack.Command.DROP,\n",
        "#         nethack.Command.EAT,\n",
        "#         # nethack.Command.ESC,\n",
        "#         nethack.Command.FIRE,\n",
        "#         nethack.Command.FIGHT,\n",
        "#         # nethack.Command.INVOKE,\n",
        "#         nethack.Command.KICK,\n",
        "#         # nethack.Command.LOOK, \n",
        "#         # nethack.Command.LOOT,\n",
        "#         # nethack.Command.OPEN,\n",
        "#         # nethack.Command.PRAY,\n",
        "#         # nethack.Command.PUTON,\n",
        "#         # nethack.Command.QUAFF,\n",
        "#         # nethack.Command.READ,\n",
        "#         # nethack.Command.REMOVE,\n",
        "#         # nethack.Command.RIDE,\n",
        "#         # nethack.Command.RUB,\n",
        "#         # nethack.Command.SEARCH,\n",
        "#         # nethack.Command.TAKEOFF,\n",
        "#         # nethack.Command.TAKEOFFALL,\n",
        "#         # nethack.Command.THROW,\n",
        "#         # nethack.Command.TIP,\n",
        "#         # nethack.Command.WEAR,\n",
        "#         nethack.Command.WIELD,\n",
        "#         # nethack.Command.ZAP,\n",
        "#     )\n",
        "#     return navActions\n",
        "\n",
        "# def customGym(maxLength=10000, seed=0):\n",
        "#     reward_gen = RewardManager()\n",
        "#     reward_gen.add_eat_event(\"apple\", reward=1, repeatable=False)\n",
        "#     reward_gen.add_wield_event(\"wand\", reward=20, repeatable=False) # changed to convince the agent finding the wand and using it is good\n",
        "#     reward_gen.add_location_event(\"sink\", reward=-1, terminal_required=False)\n",
        "#     reward_gen.add_kill_event(\"minotaur\",reward=100, repeatable=False) #minotaur guards the exit and is in the maze, which requires the WoD to do\n",
        "    \n",
        "#     # may need more rewards as we continue\n",
        "#     env = gym.make(\n",
        "#         \"MiniHack-Quest-Hard-v0\",\n",
        "#         observation_keys=(\"chars\", \"inv_letters\", \"message\"),\n",
        "#             reward_manager = reward_gen,\n",
        "#             savedir = \"./games\",\n",
        "#             actions=createActionSpace()\n",
        "#     )\n",
        "#     # print(\"Environment created\")\n",
        "#     # print(\"maxLength here represents the maxSteps possible for the agent, please ensure that the number given here is the same\\n as the number given to the BasicWrapper otherwise there is a disconnect,\\n by default their values if left unchanged and default then they are the same.\")\n",
        "#     env._max_episode_steps = maxLength\n",
        "#     env.seed(seed)\n",
        "#     return env\n"
      ],
      "metadata": {
        "id": "D8A6L3ahg9DF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeEnv():\n",
        "    global hyper_params\n",
        "    MOVE_ACTIONS = tuple(nethack.CompassDirection)\n",
        "    NAVIGATE_ACTIONS = MOVE_ACTIONS + (\n",
        "        nethack.Command.OPEN,\n",
        "        nethack.Command.SEARCH,\n",
        "        nethack.Command.LOOK, \n",
        "        nethack.Command.JUMP, \n",
        "        nethack.Command.PICKUP,\n",
        "        nethack.Command.WIELD, \n",
        "        nethack.Command.SWAP,\n",
        "        nethack.Command.EAT,\n",
        "        nethack.Command.ZAP,\n",
        "        nethack.Command.LOOT,\n",
        "        nethack.Command.PUTON,\n",
        "        nethack.Command.APPLY,\n",
        "        nethack.Command.CAST,\n",
        "        nethack.Command.DIP,\n",
        "        nethack.Command.READ,\n",
        "        nethack.Command.INVOKE,\n",
        "        nethack.Command.RUSH,\n",
        "        nethack.Command.WEAR,\n",
        "        nethack.Command.ENHANCE\n",
        "\n",
        "        # Might need more? All actions and descriptions found here\n",
        "        # https://minihack.readthedocs.io/en/latest/getting-started/action_spaces.html\n",
        "    )\n",
        "    reward_gen = RewardManager()\n",
        "    reward_gen.add_kill_event(\"minotaur\", reward=10)\n",
        "    reward_gen.add_eat_event(\"apple\", reward=1, repeatable=False)\n",
        "    reward_gen.add_kill_event(\"goblin\", reward=1)\n",
        "    reward_gen.add_kill_event(\"jackal\", reward=1)\n",
        "    reward_gen.add_kill_event(\"giant rat\", reward=1)\n",
        "    reward_gen.add_location_event(\"sink\", reward=-1, terminal_required=False)\n",
        "    strings = list()\n",
        "    strings.append(\"The door opens.\")\n",
        "    reward_gen.add_message_event(strings, reward=1)\n",
        "    # Create env with modified actions\n",
        "    # Probably can limit the observations as well\n",
        "    pixel_obs = \"pixel_crop\"\n",
        "    env = gym.make(\n",
        "        hyper_params[\"env-name\"],\n",
        "        observation_keys=(\"chars\", \"inv_letters\", \"message\"),\n",
        "        actions=NAVIGATE_ACTIONS,\n",
        "        reward_lose=-10,\n",
        "        reward_win=10,\n",
        "        penalty_step = -0.002,\n",
        "        penalty_time = 0.002,\n",
        "        reward_manager=reward_gen,\n",
        "        savedir = \"./games\",\n",
        "        max_episode_steps = hyper_params['num-steps']\n",
        "    )\n",
        "    env.seed(hyper_params[\"seed\"])\n",
        "    # env = RenderRGB(env, pixel_obs)\n",
        "    # env = gym.wrappers.Monitor(env, \"recordings\", force=True)\n",
        "    return env\n"
      ],
      "metadata": {
        "id": "nzgDOrOqyBmV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MCTS"
      ],
      "metadata": {
        "id": "z57SZ_nlfUQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reward shaping \n",
        "\n",
        "# reward_manager = RewardManager()\n",
        "# reward_manager.add_eat_event(\"apple\", reward=1)\n",
        "# reward_manager.add_wield_event(\"dagger\", reward=2)\n",
        "# reward_manager.add_wield_event(\"wand\", reward=20)\n",
        "# reward_manager.add_kill_event(\"minotaur\",reward=40)\n",
        "# reward_manager.add_location_event(\"sink\", reward=-1, terminal_required=False)\n",
        "\n",
        "# env = gym.make(\"MiniHack-Quest-Easy-v0\",reward_manager=reward_manager)\n",
        "hyper_params = {\n",
        "        \"seed\": 42,  # which seed to use\n",
        "        \"env-name\": \"MiniHack-Quest-Hard-v0\",  # name of the game\n",
        "        \"discount-factor\": 0.99,  # discount factor\n",
        "        \"num-steps\": int(5000),  # total number of steps to run the environment for\n",
        "        \"save-freq\": 500, # number of iterations between each model save\n",
        "    }\n",
        "# env = BasicWrapper(customGym()) \n",
        "env = makeEnv()"
      ],
      "metadata": {
        "id": "-xgsWlhLQ2Q0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space.n"
      ],
      "metadata": {
        "id": "8mce7fMMfZV6",
        "outputId": "0c5830af-2891-41a1-c732-a29a5700e30f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node"
      ],
      "metadata": {
        "id": "37hV5k2_gQwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State():\n",
        "\n",
        "  def __init__(self, state, reward=0,done=False,info=None):\n",
        "        # print('init state')\n",
        "        self.state_s = state\n",
        "        self.reward = reward\n",
        "        self.done = done\n",
        "        self.info = info\n",
        "        if done:\n",
        "            self.legal_actions = []\n",
        "        else:\n",
        "            self.legal_actions = list(np.arange(env.action_space.n))\n",
        "\n",
        "class MCTS():\n",
        "  '''\n",
        "  Class for MCTS node \n",
        "  '''\n",
        "  def __init__(self,state, parent=None,  parent_action=None):\n",
        "\n",
        "    self.state = state\n",
        "    self.parent = parent # parent node in MCTS\n",
        "    self.parent_action = parent_action # action that the parent took\n",
        "    self.children = [] #children of parent node \n",
        "    self.visit_count = 0 # keeps count of how many times node has been visited\n",
        "    self.rewards = defaultdict(int)\n",
        "    self.unexplored_actions = self.state.legal_actions\n",
        "\n",
        "  def expand(self,env):\n",
        "\n",
        "    '''\n",
        "    expand node and take unexplored action \n",
        "    '''\n",
        "    action = self.unexplored_actions.pop()\n",
        "\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "\n",
        "    obs = State(obs,reward,done,_)\n",
        "\n",
        "    child_node = MCTS(obs,self,action) #obs should be state \n",
        "\n",
        "    self.children.append(child_node)\n",
        "\n",
        "    return child_node, env\n",
        "\n",
        "  def back_propagate(self,reward):\n",
        "    '''\n",
        "    Back propagate reward on all nodes from leaf to root and update visit count \n",
        "    '''\n",
        "    \n",
        "    self.visit_count += 1\n",
        "    self.rewards[reward] += 1\n",
        "\n",
        "    if self.parent:\n",
        "      self.parent.back_propagate(reward)\n",
        "\n",
        "\n",
        "  def rollout_policy(self, moves):\n",
        "    #randomly selects a child node \n",
        "    '''\n",
        "    rollout policy \n",
        "    '''\n",
        "\n",
        "    return moves[np.random.randint(len(moves))]\n",
        "\n",
        "  \n",
        "  def rollout(self,env):\n",
        "    '''\n",
        "    rollout: until we reach the leaf node, randomly choose an action at each step and simulate \n",
        "    this act to receive an ave reward until done (ep is over)\n",
        "    '''\n",
        "    curr = self.state\n",
        "\n",
        "    while not curr.done:\n",
        "      moves = curr.legal_actions\n",
        "\n",
        "      act = self.rollout_policy(moves)\n",
        "\n",
        "      obs, reward, done, _ = env.step(act)\n",
        "\n",
        "      curr = State(obs,reward,done,_)\n",
        "    \n",
        "    return curr.reward\n",
        "\n",
        "  def tree_policy(self,env): #->fix \n",
        "    '''\n",
        "    keeps expanding tree until terminal node is reached \n",
        "    '''\n",
        "    # curr = self\n",
        "    # while not curr.state.done:\n",
        "    #   if len(self.children) < env.action_space.n:\n",
        "    #     return self.expand(env)\n",
        "    #   else:\n",
        "    #     curr = curr.best_child(c_param = 0.1)\n",
        "\n",
        "    # return curr, env\n",
        "\n",
        "    current_node = self\n",
        "    while not current_node.state.done:\n",
        "\n",
        "        if len(current_node.children)==0:\n",
        "            return current_node.expand(env)\n",
        "        elif random.uniform(0,1)<.5:\n",
        "            current_node = current_node.best_child()\n",
        "        else:\n",
        "            if not len(current_node.unexplored_actions) == 0:\n",
        "                return current_node.expand(env)\n",
        "            else:\n",
        "                current_node = current_node.best_child()\n",
        "    return current_node , env\n",
        "\n",
        "  \n",
        "  \n",
        "  def n(self):\n",
        "    return self.visit_count\n",
        "\n",
        "  def q(self):\n",
        "    # wins = self._results[1]\n",
        "    # loses = self._results[-1]\n",
        "    # return wins - loses\n",
        "\n",
        "    total = 0\n",
        "    for r in self.rewards:\n",
        "        total += r*self.rewards[r]\n",
        "\n",
        "    return total\n",
        "\n",
        "  def best_child(self, c_param=0.1):\n",
        "    \n",
        "    # choices_weights = [(c.q() / c.n()) + c_param * np.sqrt((2 * np.log(self.n()) / c.n())) for c in self.children]\n",
        "    # print(choices_weights)\n",
        "    # return self.children[np.argmax(choices_weights)]\n",
        "\n",
        "    choices_weights = [(c.q() / c.n()) + c_param * np.sqrt((2 * np.log(self.n()) / c.n())) for c in self.children]\n",
        "    child = np.random.choice(np.flatnonzero(choices_weights == max(choices_weights)))\n",
        "    return self.children[child]\n",
        "\n",
        "  def best_action(self,actions):\n",
        "    simulation_no = 70\n",
        "\t\n",
        "\t\n",
        "    for i in range(simulation_no):\n",
        "      new_env = env = makeEnv()\n",
        "      # new_env = BasicWrapper(customGym()) \n",
        "      new_init_state = new_env.reset()\n",
        "\n",
        "      for a in actions:\n",
        "        obs,reward,done,_ = new_env.step(a)\n",
        "\n",
        "      v = self.tree_policy(new_env)\n",
        "      reward = v[0].rollout(v[1])\n",
        "      v[0].back_propagate(reward)\n",
        "\t\n",
        "    return self.best_child(c_param=0.1)\n",
        "\n",
        "  \n",
        "  # def best_child(self,c_p):\n",
        "  #   '''\n",
        "  #   finds best child using UCT\n",
        "  #   xi is ave reward/value of all nodes beneath this node \n",
        "  #   ns is the numer of times the parent has been visited\n",
        "  #   ni is the numer of times the child node i has been visited\n",
        "  #   '''\n",
        "\n",
        "  #   ns = self.visit_count #visit count of parent\n",
        "\n",
        "  #   ni = [c.visit_count for c in self.children] #visit count of chilren \n",
        "\n",
        "  #   q = 0\n",
        "  #   for r in self.rewards:\n",
        "  #     q += r*self.rewards[r]\n",
        "\n",
        "  #   first_term = q / ni\n",
        "\n",
        "  #   second_term = c_p * np.sqrt((2*np.log(ns))/ni) \n",
        "\n",
        "  #   UCB1 = first_term + second_term \n",
        "\n",
        "  #   best_child = np.argmax(UCB1)\n",
        "\n",
        "  #   return self.children[best_child]\n",
        "\n",
        "  # def best_action(self):\n",
        "  #   '''\n",
        "  #   find next best action \n",
        "  #   '''\n",
        "\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "QstfHIxqfU-m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "DNk7Sj411Nmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    iters =1000\n",
        "\n",
        "    for mpx in range(1):\n",
        "        \n",
        "\n",
        "        prev_actions = []\n",
        "        rewards = []\n",
        "        actionsTaken = []\n",
        "        \n",
        "        env = env = makeEnv()\n",
        "        # env = BasicWrapper(customGym()) \n",
        "        \n",
        "        rewardArr = []\n",
        "        \n",
        "        initial_state = env.reset()\n",
        "        initial_state = State(state = initial_state)\n",
        "        # env.render()\n",
        "\n",
        "        root = MCTS(state = initial_state)\n",
        "     \n",
        "        selected_node = root.best_action(prev_actions)\n",
        "       \n",
        "        prev_actions.append(selected_node.parent_action)\n",
        "\n",
        "\n",
        "        next_state, reward, done, info = env.step(selected_node.parent_action)\n",
        "\n",
        "        # rewards.append(reward)\n",
        "        next_state = State(next_state,reward,done,info)\n",
        "\n",
        "    \n",
        "        cnt = 0\n",
        "        \n",
        "        # loops through the rest of the game repeatedly calling the \n",
        "        # best_action function and making the selected move in the environment\n",
        "        for it in range(iters):\n",
        "            if done:\n",
        "                print(\"im done\")\n",
        "                break;\n",
        "            cnt += 1\n",
        "            print(\"Current Game {0}, current step {1}\".format(mpx, cnt))\n",
        "            selected_node = MCTS(state = next_state)\n",
        "            selected_node = selected_node.best_action(prev_actions)\n",
        "\n",
        "\n",
        "            prev_actions.append(selected_node.parent_action)\n",
        "\n",
        "            next_state, reward, done, info = env.step(selected_node.parent_action)\n",
        "            rewards.append(reward)\n",
        "            print(\"reward: {}\".format(reward))\n",
        "\n",
        "            next_state = State(next_state,reward,done,info)\n",
        "\n",
        "        rewardArr = np.array(rewards)\n",
        "        # saves the rewards received during game\n",
        "        # np.savetxt(\"rewardArr-{0}\".format(mpx), rewardArr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "7kru-NQj1NG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "53f99079-5533-47d9-8de8-09d3054336e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Game 0, current step 1\n",
            "reward: -0.002\n",
            "Current Game 0, current step 2\n",
            "reward: -0.002\n",
            "Current Game 0, current step 3\n",
            "reward: -0.002\n",
            "Current Game 0, current step 4\n",
            "reward: -0.002\n",
            "Current Game 0, current step 5\n",
            "reward: -0.002\n",
            "Current Game 0, current step 6\n",
            "reward: -0.002\n",
            "Current Game 0, current step 7\n",
            "reward: -0.002\n",
            "Current Game 0, current step 8\n",
            "reward: -0.002\n",
            "Current Game 0, current step 9\n",
            "reward: -0.002\n",
            "Current Game 0, current step 10\n",
            "reward: -0.002\n",
            "Current Game 0, current step 11\n",
            "reward: -0.002\n",
            "Current Game 0, current step 12\n",
            "reward: -0.002\n",
            "Current Game 0, current step 13\n",
            "reward: -0.002\n",
            "Current Game 0, current step 14\n",
            "reward: -0.002\n",
            "Current Game 0, current step 15\n",
            "reward: -0.002\n",
            "Current Game 0, current step 16\n",
            "reward: -0.002\n",
            "Current Game 0, current step 17\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-25a460e10567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-25a460e10567>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current Game {0}, current step {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mselected_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mselected_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-0ce644c829a8>\u001b[0m in \u001b[0;36mbest_action\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0mnew_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;31m# new_env = BasicWrapper(customGym())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mnew_init_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-fd5ce10d66c2>\u001b[0m in \u001b[0;36mmakeEnv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mreward_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0msavedir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./games\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mmax_episode_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num-steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/minihack/envs/skills_quest.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_episode_steps\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_episode_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"quest_hard.des\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/minihack/skills.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, des_file, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;34m\"observation_keys\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         )\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdes_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/minihack/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, des_file, reward_win, reward_lose, obs_crop_h, obs_crop_w, obs_crop_pad, reward_manager, use_wiki, autopickup, pet, observation_keys, seeds, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Patch the nhdat library by compling the given .des file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdes_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_crop_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_crop_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/minihack/base.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, des_file)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;34m\"\"\"Update the current environment by replacing its description file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_patch_nhdat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdes_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_patch_nhdat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/minihack/base.py\u001b[0m in \u001b[0;36m_patch_nhdat\u001b[0;34m(self, des_file)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mHACKDIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0mLIB_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                     \u001b[0mdes_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m                 ]\n\u001b[1;32m    394\u001b[0m             )\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(1.900000000000000022e-01)\n",
        "# 1.600000000000000311e-01\n",
        "# 1.600000000000000311e-01\n",
        "# 1.900000000000000022e-01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wjSCPteTuSo",
        "outputId": "9f296109-d1d4-4af3-fccc-c0cdbef9f35c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m1ZS-SPr8luk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}